# üìù Nastƒôpne kroki - Doko≈Ñczenie projektu

## ‚úÖ Co zosta≈Ço utworzone:

1. ‚úÖ Struktura katalog√≥w projektu
2. ‚úÖ **docs/CURSOR.md** - Pe≈Çna dokumentacja projektu
3. ‚úÖ **README.md** - Instrukcja instalacji
4. ‚úÖ **requirements.txt** - Wszystkie zale≈ºno≈õci (ZAINSTALOWANE!)
5. ‚úÖ **src/preprocessing.py** - Modu≈Ç preprocessingu obraz√≥w
6. ‚úÖ **src/feature_extraction.py** - Modu≈Ç ekstrakcji cech
7. ‚úÖ **src/classification.py** - Modu≈Ç klasyfikacji
8. ‚úÖ **notebooks/01_eksploracja_danych.ipynb** - Gotowy notebook EDA
9. ‚úÖ ≈örodowisko wirtualne `venv/` z zainstalowanymi pakietami

---

## üéØ Co musisz jeszcze zrobiƒá:

### 1. Pobraƒá dataset Fruits 360

**Krok 1**: Pobierz dataset
- Link: https://www.kaggle.com/datasets/moltean/fruits
- Pobierz ZIP (mo≈ºe wymagaƒá konta Kaggle - darmowe)

**Krok 2**: Rozpakuj do projektu
```bash
cd /Users/thomasross/Projects/wsb/multimedia/data/raw/
# Tutaj rozpakuj zawarto≈õƒá ZIP
# Powinna powstaƒá struktura:
# data/raw/
#   ‚îú‚îÄ‚îÄ Training/
#   ‚îî‚îÄ‚îÄ Test/
```

---

### 2. Uruchomiƒá Jupyter Notebook

```bash
cd /Users/thomasross/Projects/wsb/multimedia
source venv/bin/activate
jupyter notebook
```

Przejd≈∫ do `notebooks/01_eksploracja_danych.ipynb` i uruchom wszystkie kom√≥rki!

---

### 3. Utworzyƒá pozosta≈Çe notebooki

#### Notebook 02: Ekstrakcja cech

Utworzy≈Çem dla Ciebie szablon. Utw√≥rz plik `notebooks/02_ekstrakcja_cech.ipynb` i dodaj:

**G≈Ç√≥wne sekcje**:
1. Import modu≈Ç√≥w
2. Demonstracja ekstrakcji na 1 obrazie
3. Wizualizacja cech (histogramy, kszta≈Çty, LBP)
4. Pƒôtla po wszystkich obrazach
5. Zapis do CSV (`data/processed/features_train.csv`, `features_test.csv`)

**Kod - g≈Ç√≥wna funkcja ekstrakcji**:
```python
from preprocessing import load_and_preprocess, get_all_image_paths, extract_label_from_path
from feature_extraction import extract_all_features, get_feature_names
import pandas as pd
from tqdm import tqdm

def extract_dataset_features(split='Training', use_subset=True, n_classes=20):
    """Ekstrahuje cechy z datasetu"""
    data_dir = Path(f'../data/raw/{split}')
    
    # Pobierz klasy
    all_classes = sorted([d.name for d in data_dir.iterdir() if d.is_dir()])
    if use_subset:
        selected_classes = all_classes[:n_classes]
    else:
        selected_classes = all_classes
    
    features_list = []
    labels = []
    
    for class_name in selected_classes:
        class_dir = data_dir / class_name
        for img_path in tqdm(list(class_dir.glob('*.jpg')), desc=class_name):
            try:
                img = load_and_preprocess(str(img_path))
                features = extract_all_features(img)
                features_list.append(features)
                labels.append(class_name)
            except:
                continue
    
    # DataFrame
    feature_names = get_feature_names()
    df = pd.DataFrame(features_list, columns=feature_names)
    df['label'] = labels
    
    return df

# U≈ºyj:
df_train = extract_dataset_features('Training', use_subset=True, n_classes=20)
df_train.to_csv('../data/processed/features_train.csv', index=False)

df_test = extract_dataset_features('Test', use_subset=True, n_classes=20)
df_test.to_csv('../data/processed/features_test.csv', index=False)
```

---

#### Notebook 03: Klasyfikacja

Utw√≥rz `notebooks/03_klasyfikacja.ipynb`:

**G≈Ç√≥wne sekcje**:
1. Wczytanie cech z CSV
2. Preprocessing (StandardScaler, train/test split)
3. Trenowanie modeli:
   - SVM
   - Random Forest
   - k-NN
   - Decision Tree
4. Por√≥wnanie wynik√≥w
5. Confusion matrix
6. Feature importance (dla RF)
7. Zapis najlepszego modelu

**Przyk≈Çadowy kod**:
```python
from classification import (
    prepare_data,
    get_svm_classifier,
    get_random_forest_classifier,
    get_knn_classifier,
    train_and_evaluate,
    plot_confusion_matrix,
    plot_model_comparison,
    save_model
)

# Wczytaj dane
df_train = pd.read_csv('../data/processed/features_train.csv')
df_test = pd.read_csv('../data/processed/features_test.csv')

X_train = df_train.drop(['label', 'image_path'], axis=1, errors='ignore')
y_train = df_train['label']
X_test = df_test.drop(['label', 'image_path'], axis=1, errors='ignore')
y_test = df_test['label']

# Przygotuj dane
X_train_scaled, X_test_scaled, y_train_enc, y_test_enc, scaler, le = prepare_data(
    X_train.values, y_train.values
)

# Trenuj modele
results = {}

# SVM
svm_model = get_svm_classifier(kernel='rbf', C=10)
results['SVM'] = train_and_evaluate(svm_model, X_train_scaled, y_train_enc, 
                                     X_test_scaled, y_test_enc, 'SVM')

# Random Forest
rf_model = get_random_forest_classifier(n_estimators=100, max_depth=20)
results['Random Forest'] = train_and_evaluate(rf_model, X_train_scaled, y_train_enc,
                                               X_test_scaled, y_test_enc, 'Random Forest')

# k-NN
knn_model = get_knn_classifier(n_neighbors=5)
results['k-NN'] = train_and_evaluate(knn_model, X_train_scaled, y_train_enc,
                                      X_test_scaled, y_test_enc, 'k-NN')

# Por√≥wnaj
plot_model_comparison(results, metric='test_accuracy')

# Confusion matrix dla najlepszego
best_model_name = max(results, key=lambda k: results[k]['test_accuracy'])
best_result = results[best_model_name]
plot_confusion_matrix(y_test_enc, best_result['y_pred_test'], 
                     labels=le.classes_, title=f'Confusion Matrix - {best_model_name}')

# Zapisz najlepszy model
save_model(best_result['model'], f'../results/models/{best_model_name.lower()}_model.pkl',
          scaler, le)
```

---

#### Notebook 04: Raport Final (G≈Å√ìWNY RAPORT)

To bƒôdzie Tw√≥j **g≈Ç√≥wny raport do prezentacji**!

Utw√≥rz `notebooks/04_raport_final.ipynb`:

**Struktura raportu**:

1. **Wprowadzenie**
   - Cel projektu
   - Teza: CNN nie sƒÖ konieczne
   - Dataset Fruits 360

2. **Metodologia**
   - Klasyczne metody przetwarzania obraz√≥w
   - Ekstrahowane cechy:
     - Kolor (histogramy RGB/HSV, momenty)
     - Kszta≈Çt (area, perimeter, Hu moments)
     - Tekstura (LBP, GLCM)

3. **Eksperymenty**
   - Dataset: X klas, Y obraz√≥w
   - Cechy: Z features
   - Modele: SVM, Random Forest, k-NN, Decision Tree

4. **Wyniki**
   - Tabela z accuracy dla ka≈ºdego modelu
   - Wykresy por√≥wnawcze
   - Confusion matrix najlepszego modelu
   - Feature importance

5. **Wnioski**
   - OsiƒÖgniƒôta accuracy: ~85-90%?
   - Por√≥wnanie z CNN (literatura: ~98%)
   - **Wnioski**:
     - Klasyczne metody sƒÖ wystarczajƒÖce dla prostych zada≈Ñ
     - CNN potrzebne gdy: z≈Ço≈ºone t≈Ça, r√≥≈ºne skale, rotacje, occlusion
     - Zalety klasycznych: interpretowalno≈õƒá, szybko≈õƒá, mniej danych
     - Wady: rƒôczne feature engineering, gorsze dla z≈Ço≈ºonych danych

6. **Podsumowanie prezentacji**

---

## üìä Przyk≈Çadowe wyniki (do raportu)

| Model | Train Accuracy | Test Accuracy | Precision | Recall | F1-Score |
|-------|---------------|---------------|-----------|--------|----------|
| SVM | 0.92 | 0.87 | 0.86 | 0.87 | 0.86 |
| **Random Forest** | **0.95** | **0.89** | **0.88** | **0.89** | **0.88** |
| k-NN | 0.88 | 0.83 | 0.82 | 0.83 | 0.82 |
| Decision Tree | 0.89 | 0.75 | 0.74 | 0.75 | 0.74 |

**Najlepszy model**: Random Forest - 89% accuracy

---

## üé§ Przygotowanie prezentacji

### Slajdy (opcjonalnie - lub tylko Jupyter Notebook)

1. **Slajd 1**: Tytu≈Ç
   - "Klasyfikacja Owoc√≥w - Metody Klasyczne vs CNN"
   - Autorzy, data

2. **Slajd 2**: Problem
   - Czy CNN sƒÖ jedynym rozwiƒÖzaniem?
   - Dataset: Fruits 360 (131 klas)

3. **Slajd 3**: Metodologia
   - Wykres: preprocessing ‚Üí feature extraction ‚Üí classification
   - Typy cech: kolor, kszta≈Çt, tekstura

4. **Slajd 4**: Wizualizacje cech
   - Przyk≈Çadowy owoc
   - Histogramy, kontury, LBP

5. **Slajd 5**: Wyniki
   - Tabela accuracy
   - Wykres s≈Çupkowy por√≥wnania modeli

6. **Slajd 6**: Confusion Matrix
   - Najlepszy model

7. **Slajd 7**: Wnioski
   - Klasyczne metody: 85-90%
   - CNN: ~98% (literatura)
   - Kiedy klasyczne sƒÖ OK, kiedy CNN konieczne

8. **Slajd 8**: Podsumowanie
   - Q&A

**LUB** wyeksportuj notebook 04 do HTML:
```bash
jupyter nbconvert --to html notebooks/04_raport_final.ipynb
```

---

## ‚è∞ Timeline

**Tydzie≈Ñ 1**:
- [x] Setup projektu
- [ ] Pobraƒá dataset
- [ ] Uruchomiƒá notebook 01
- [ ] Utworzyƒá notebook 02 i wyekstrahowaƒá cechy

**Tydzie≈Ñ 2**:
- [ ] Utworzyƒá notebook 03 i wytrenowaƒá modele
- [ ] Utworzyƒá notebook 04 (raport)

**Tydzie≈Ñ 3**:
- [ ] Przygotowaƒá prezentacjƒô
- [ ] Przeƒáwiczyƒá timing (10 min)
- [ ] Prezentacja na zajƒôciach

---

## üÜò Troubleshooting

### Problem: Dataset zbyt du≈ºy, ekstrakcja trwa za d≈Çugo
**RozwiƒÖzanie**: U≈ºyj podzbioru klas
```python
USE_SUBSET = True
SUBSET_SIZE = 20  # Zamiast wszystkich 131 klas
```

### Problem: Za ma≈Ço RAM
**RozwiƒÖzanie**: Przetwarzaj partiami i zapisuj do CSV czƒô≈õciami

### Problem: Niska accuracy (<70%)
**RozwiƒÖzanie**: 
- Sprawd≈∫ czy preprocessing dzia≈Ça (bia≈Çe t≈Ço usuniƒôte?)
- U≈ºyj wiƒôcej klas treningowych
- Tune hyperparameters (Grid Search)

---

## üìö Dodatkowe zasoby

- OpenCV Tutorial: https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html
- scikit-learn Guide: https://scikit-learn.org/stable/user_guide.html
- Fruits 360 Paper: https://arxiv.org/abs/1712.00580

---

## ‚úÖ Checklist przed prezentacjƒÖ

- [ ] Wszystkie 4 notebooki dzia≈ÇajƒÖ
- [ ] Wyniki zapisane (modele, wykresy)
- [ ] Raport/prezentacja gotowa
- [ ] Pr√≥ba prezentacji (timing 10 min)
- [ ] Odpowiedzi na pytania przygotowane

---

**Powodzenia! üçÄ**

Je≈õli masz pytania, sprawd≈∫ `docs/CURSOR.md` lub dokumentacjƒô w kodzie.

