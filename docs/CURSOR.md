# ğŸ Projekt: Klasyfikacja OwocÃ³w - Metody Klasyczne vs CNN

## ğŸ“Œ Informacje podstawowe

**Temat**: Sieci konwolucyjne nie sÄ… rozwiÄ…zaniem na wszystko - klasyczna analiza obrazÃ³w owocÃ³w

**Cel**: UdowodniÄ‡, Å¼e klasyczne metody przetwarzania obrazÃ³w i ekstrakcji cech mogÄ… skutecznie klasyfikowaÄ‡ owoce bez uÅ¼ywania CNN (Convolutional Neural Networks)

**Grupa**: 2 osoby

**Dataset**: Fruits 360 - podzbiÃ³r (48 klas, ~47,000 obrazÃ³w)
- 3 kategorie: Apple (22), Cherry (12), Tomato (14)
- 34,800 train + 12,233 test obrazÃ³w

---

## ğŸ¯ ZaÅ‚oÅ¼enia projektu

### âŒ ZABRONIONE:
- Sieci neuronowe (CNN, ANN, Deep Learning)
- Transfer learning z gotowych modeli
- Automatyczna ekstrakcja cech przez sieci

### âœ… DOZWOLONE:
- Klasyczne metody przetwarzania obrazÃ³w
- RÄ™czna ekstrakcja cech (ksztaÅ‚t, kolor, tekstura)
- Klasyczne algorytmy ML (SVM, Random Forest, k-NN, Decision Tree)
- Biblioteki: OpenCV, scikit-image, scikit-learn

---

## ğŸ“Š Dataset: Fruits 360 (podzbiÃ³r)

**Å¹rÃ³dÅ‚o**: Kaggle - Fruits 360 Dataset
- **Link**: https://www.kaggle.com/datasets/moltean/fruits

**Charakterystyka uÅ¼ywanego podzbioru**:
- **48 klas** owocÃ³w i warzyw (podzbiÃ³r z 131 dostÄ™pnych)
- **47,033 obrazÃ³w** Å‚Ä…cznie
  - **34,800 obrazÃ³w treningowych**
  - **12,233 obrazÃ³w testowych**
- Rozmiar: 100x100 pikseli
- Czyste biaÅ‚e tÅ‚o
- RÃ³Å¼ne kÄ…ty obrotu tego samego owocu
- Format: JPG

**Statystyki (z notebooka 01_eksploracja_danych_v2.ipynb)**:
- Min obrazÃ³w na klasÄ™ (train): 304
- Max obrazÃ³w na klasÄ™ (train): 984
- Åšrednia obrazÃ³w na klasÄ™: 725.0

**Kategorie w projekcie (3 gÅ‚Ã³wne)**:
1. **Apple** (22 odmiany):
   - Apple 5, 7, 8, 9, 11, 12, 13, 14, 17, 18
   - Apple Braeburn, Crimson Snow, Golden 2, Golden 3
   - Apple Pink Lady, Red 2, Red 3, Red Delicious, Red Yellow 2
   - Apple Rotten, hit, worm

2. **Cherry** (12 odmian):
   - Cherry 1, 2, 4, 5
   - Cherry Rainier 2, Rainier 3, Sour 1
   - Cherry Wax Black 1, Wax Red 1, Wax Red 2, Wax Yellow 1
   - Cherry Wax not ripen 2

3. **Tomato** (14 odmian):
   - Tomato 2, 3, 4, 5, 8, 9, 10
   - Tomato Cherry Maroon 1, Cherry Orange 1, Cherry Red 2, Cherry Yellow 1
   - Tomato Heart 1, Maroon 2, not Ripen 1

**Uwaga**: Projekt uÅ¼ywa podzbioru dla efektywnoÅ›ci i szybszego przetwarzania. PeÅ‚ny dataset (131 klas) moÅ¼na pobraÄ‡ z Kaggle.

---

## ğŸ”¬ Metodologia

### 1. Preprocessing (Przetwarzanie wstÄ™pne)
```python
# Kroki:
1. Wczytanie obrazu
2. UsuniÄ™cie biaÅ‚ego tÅ‚a (segmentacja)
3. Normalizacja rozmiaru
4. Konwersja przestrzeni kolorÃ³w (RGB â†’ HSV, LAB)
```

### 2. Ekstrakcja cech (Feature Extraction)

#### A. **Cechy koloru** (Color Features)
- **Histogram RGB**: rozkÅ‚ad intensywnoÅ›ci w kanaÅ‚ach R, G, B
- **Histogram HSV**: odcieÅ„ (Hue), nasycenie (Saturation), wartoÅ›Ä‡ (Value)
- **Momenty koloru**: Å›rednia, odchylenie standardowe, skewness, kurtosis
- **DominujÄ…cy kolor**: k-means clustering w przestrzeni kolorÃ³w

#### B. **Cechy ksztaÅ‚tu** (Shape Features)
- **Area**: pole powierzchni owocu
- **Perimeter**: obwÃ³d konturu
- **Circularity**: 4Ï€ Ã— Area / PerimeterÂ² (miara okrÄ…gÅ‚oÅ›ci)
- **Aspect Ratio**: stosunek szerokoÅ›ci do wysokoÅ›ci
- **Extent**: stosunek obszaru obiektu do obszaru bounding box
- **Solidity**: stosunek obszaru do convex hull area
- **Momenty Hu**: 7 niezmiennikÃ³w momentÃ³w (invariant to translation, rotation, scale)

#### C. **Cechy tekstury** (Texture Features)
- **LBP** (Local Binary Patterns): histogram LBP
- **GLCM** (Gray-Level Co-occurrence Matrix):
  - Contrast (kontrast)
  - Correlation (korelacja)
  - Energy (energia)
  - Homogeneity (jednorodnoÅ›Ä‡)
- **Haralick features**: 13 cech tekstury z GLCM

#### D. **Inne cechy**
- **HOG** (Histogram of Oriented Gradients) - opcjonalnie
- **Edge density**: gÄ™stoÅ›Ä‡ krawÄ™dzi (Canny)

### 3. Klasyfikacja (Classification)

PorÃ³wnanie klasycznych algorytmÃ³w:

#### **SVM** (Support Vector Machine)
- Kernel: RBF, Linear, Polynomial
- Hyperparameters: C, gamma

#### **Random Forest**
- Ensemble metoda
- Hyperparameters: n_estimators, max_depth, min_samples_split

#### **k-NN** (k-Nearest Neighbors)
- Hyperparameters: k (liczba sÄ…siadÃ³w), metric (euclidean, manhattan)

#### **Decision Tree**
- Hyperparameters: max_depth, min_samples_leaf

### 4. Ewaluacja

**Metryki**:
- Accuracy (dokÅ‚adnoÅ›Ä‡)
- Precision, Recall, F1-Score
- Confusion Matrix
- Classification Report
- ROC curves (dla binary classification)

**Cross-validation**: 5-fold lub 10-fold

---

## ğŸ“ Struktura projektu

```
multimedia/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ CURSOR.md              # Ten plik - dokumentacja projektu
â”‚   â””â”€â”€ prezentacja.md         # Notatki do prezentacji koÅ„cowej
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Surowe obrazy Fruits 360
â”‚   â”‚   â”œâ”€â”€ Training/          # ZbiÃ³r treningowy
â”‚   â”‚   â””â”€â”€ Test/              # ZbiÃ³r testowy
â”‚   â””â”€â”€ processed/             # Przetworzone dane (CSV z cechami)
â”‚       â”œâ”€â”€ features_train.csv
â”‚       â””â”€â”€ features_test.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eksploracja_danych.ipynb      # EDA - wersja 1
â”‚   â”œâ”€â”€ 01_eksploracja_danych_v2.ipynb   # âœ… GÅÃ“WNY NOTEBOOK - EDA z komentarzami i ÅºrÃ³dÅ‚ami
â”‚   â”œâ”€â”€ 02_ekstrakcja_cech.ipynb         # TODO: Implementacja ekstrakcji cech
â”‚   â”œâ”€â”€ 03_klasyfikacja.ipynb            # TODO: Trenowanie i porÃ³wnanie modeli
â”‚   â””â”€â”€ 04_raport_final.ipynb            # TODO: GÅÃ“WNY RAPORT do prezentacji
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ preprocessing.py       # Funkcje przetwarzania obrazÃ³w
â”‚   â”œâ”€â”€ feature_extraction.py  # Funkcje ekstrakcji cech
â”‚   â””â”€â”€ classification.py      # Funkcje klasyfikacji i ewaluacji
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/              # Wykresy, wizualizacje
â”‚   â”‚   â”œâ”€â”€ eda/
â”‚   â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ models/
â”‚   â””â”€â”€ models/               # Zapisane wytrenowane modele
â”‚       â”œâ”€â”€ svm_model.pkl
â”‚       â”œâ”€â”€ rf_model.pkl
â”‚       â””â”€â”€ knn_model.pkl
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt          # ZaleÅ¼noÅ›ci Python
â””â”€â”€ README.md                # Instrukcja instalacji i uruchomienia
```

---

## ğŸš€ Instalacja i uruchomienie

### 1. Klonowanie/Setup projektu
```bash
cd /Users/thomasross/Projects/wsb/multimedia
```

### 2. Utworzenie Å›rodowiska wirtualnego
```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux
```

### 3. Instalacja zaleÅ¼noÅ›ci
```bash
pip install -r requirements.txt
```

### 4. Pobranie datasetu Fruits 360

**Opcja A - Kaggle API** (wymaga konta Kaggle):
```bash
pip install kaggle
kaggle datasets download -d moltean/fruits
unzip fruits.zip -d data/raw/
```

**Opcja B - RÄ™cznie**:
1. Pobierz z: https://www.kaggle.com/datasets/moltean/fruits
2. Rozpakuj do `data/raw/`
3. Struktura:
   ```
   data/raw/
   â”œâ”€â”€ Training/
   â”‚   â”œâ”€â”€ Apple Braeburn/
   â”‚   â”œâ”€â”€ Apple Golden 1/
   â”‚   â””â”€â”€ ...
   â””â”€â”€ Test/
       â”œâ”€â”€ Apple Braeburn/
       â”œâ”€â”€ Apple Golden 1/
       â””â”€â”€ ...
   ```

### 5. Uruchomienie notebookÃ³w
```bash
jupyter notebook
```

OtwÃ³rz notebooki w kolejnoÅ›ci:
1. `01_eksploracja_danych_v2.ipynb` â† **âœ… UKOÅƒCZONY - z dokumentacjÄ… i ÅºrÃ³dÅ‚ami**
2. `02_ekstrakcja_cech.ipynb` â† TODO
3. `03_klasyfikacja.ipynb` â† TODO
4. `04_raport_final.ipynb` â† TODO (gÅ‚Ã³wny raport)

---

## ğŸ“ˆ Workflow projektu

### Krok 1: Eksploracja danych (EDA)
- Wczytanie przykÅ‚adowych obrazÃ³w
- Wizualizacja rÃ³Å¼nych klas
- Analiza rozkÅ‚adu klas
- Sprawdzenie rozmiaru datasetu

### Krok 2: Ekstrakcja cech
- Implementacja funkcji do ekstrakcji cech
- Przetworzenie wszystkich obrazÃ³w train/test
- Zapisanie cech do CSV
- Analiza waÅ¼noÅ›ci cech

### Krok 3: Klasyfikacja
- Trenowanie rÃ³Å¼nych klasyfikatorÃ³w
- Hyperparameter tuning (Grid Search)
- PorÃ³wnanie wynikÃ³w
- Wizualizacja confusion matrix

### Krok 4: Raport koÅ„cowy
- Podsumowanie wynikÃ³w
- Najlepszy model
- Wnioski: czy CNN sÄ… konieczne?
- Przygotowanie do prezentacji

---

## ğŸ“Š Oczekiwane wyniki

### Hipotezy:
1. **SVM z cechami koloru i ksztaÅ‚tu** powinien osiÄ…gnÄ…Ä‡ >80% accuracy
2. **Random Forest** moÅ¼e daÄ‡ najlepsze wyniki (~85-90%)
3. **Cechy koloru** bÄ™dÄ… najwaÅ¼niejsze (rÃ³Å¼ne owoce = rÃ³Å¼ne kolory)
4. **Cechy ksztaÅ‚tu** pomogÄ… rozrÃ³Å¼niÄ‡ jabÅ‚ka od bananÃ³w
5. **Tekstura** moÅ¼e byÄ‡ mniej istotna przy biaÅ‚ym tle

### Benchmark bez CNN:
- **Target accuracy**: >85% na 48 klasach
- **Baseline**: Random guess = 1/48 â‰ˆ 2.08%

### PorÃ³wnanie z CNN:
- Typowa CNN na Fruits 360: ~98-99% accuracy
- **Nasza metoda**: pokaÅ¼e, Å¼e moÅ¼na osiÄ…gnÄ…Ä‡ ~85-90% bez CNN!

### Analiza zbalansowania klas:
- Minimum: 304 obrazÃ³w na klasÄ™
- Maximum: 984 obrazÃ³w na klasÄ™  
- Åšrednia: 725 obrazÃ³w na klasÄ™
- Dataset jest stosunkowo zbalansowany

---

## ğŸ¤ Prezentacja (ostatnie zajÄ™cia)

### Plan prezentacji (2 osoby):

#### Osoba 1 (5 min):
1. **Wprowadzenie**:
   - Problem: Czy CNN sÄ… konieczne?
   - Dataset: Fruits 360
   - Metodologia: klasyczne metody

2. **Ekstrakcja cech**:
   - Demonstracja cech na przykÅ‚adach
   - Wizualizacje: histogramy kolorÃ³w, kontury, tekstury

#### Osoba 2 (5 min):
3. **Klasyfikacja i wyniki**:
   - PorÃ³wnanie algorytmÃ³w (SVM, RF, k-NN)
   - Confusion matrix
   - Najlepszy model

4. **Wnioski**:
   - OsiÄ…gniÄ™ta accuracy
   - Kiedy CNN sÄ… konieczne, a kiedy nie?
   - Zalety metod klasycznych: interpretowalnoÅ›Ä‡, szybkoÅ›Ä‡

**MateriaÅ‚y do prezentacji**:
- Jupyter Notebook: `04_raport_final.ipynb`
- Eksport do HTML/PDF z wynikami
- Slajdy (opcjonalnie): PowerPoint z kluczowymi wizualizacjami

---

## ğŸ› ï¸ UÅ¼yte technologie

### JÄ™zyki i narzÄ™dzia:
- **Python 3.8+**
- **Jupyter Notebook**

### Biblioteki:
- **OpenCV** (`cv2`): przetwarzanie obrazÃ³w
- **scikit-image**: segmentacja, ekstrakcja cech
- **scikit-learn**: klasyfikacja, metryki
- **NumPy, Pandas**: operacje na danych
- **Matplotlib, Seaborn**: wizualizacje
- **Pillow (PIL)**: obsÅ‚uga obrazÃ³w

---

## ğŸ“š Literatura i zasoby

### Dataset:
- Fruits 360: https://www.kaggle.com/datasets/moltean/fruits
- Paper: MureÈ™an, H., & Oltean, M. (2018). "Fruit recognition from images using deep learning"

### Metody klasyczne:
- **Hu Moments**: M. K. Hu (1962). "Visual pattern recognition by moment invariants"
- **LBP**: Ojala et al. (2002). "Multiresolution gray-scale and rotation invariant texture classification"
- **GLCM**: Haralick et al. (1973). "Textural Features for Image Classification"

### Tutorials:
- OpenCV Documentation: https://docs.opencv.org/
- scikit-image Examples: https://scikit-image.org/docs/stable/auto_examples/
- scikit-learn User Guide: https://scikit-learn.org/stable/user_guide.html

---

## âœ… Checklist projektu

### Przed prezentacjÄ…:
- [x] Pobranie i rozpakownie datasetu Fruits 360 (podzbiÃ³r 48 klas)
- [x] UkoÅ„czenie notebooka 01: Eksploracja danych (`01_eksploracja_danych_v2.ipynb`)
  - [x] Analiza struktury datasetu
  - [x] Wizualizacja przykÅ‚adowych obrazÃ³w
  - [x] Preprocessing (usuwanie tÅ‚a)
  - [x] Histogramy kolorÃ³w (RGB, HSV)
  - [x] CLAHE i sharpening
  - [x] LBP (Local Binary Patterns)
  - [x] Ekstrakcja cech ksztaÅ‚tu
  - [x] Data augmentation
  - [x] Przestrzenie kolorÃ³w (RGB, HSV, LAB)
  - [x] Dodanie komentarzy z dokumentacjÄ… i ÅºrÃ³dÅ‚ami
- [ ] UkoÅ„czenie notebooka 02: Ekstrakcja cech
- [ ] UkoÅ„czenie notebooka 03: Klasyfikacja
- [ ] UkoÅ„czenie notebooka 04: Raport koÅ„cowy
- [ ] Eksport raportu do HTML/PDF
- [ ] Przygotowanie slajdÃ³w (opcjonalnie)
- [ ] PrÃ³ba prezentacji (timing 10 min)
- [ ] Zapisanie najlepszych modeli

### Podczas prezentacji:
- [ ] Pokazanie datasetu
- [ ] Demonstracja ekstrakcji cech na Å¼ywo
- [ ] Prezentacja wynikÃ³w klasyfikacji
- [ ] Odpowiedzi na pytania prowadzÄ…cego

---

## ğŸ“ Kryteria oceny (przewidywane)

1. **PoprawnoÅ›Ä‡ metodologiczna** (30%):
   - Czy uÅ¼yto tylko metod klasycznych?
   - Czy ekstrakcja cech jest poprawna?

2. **Wyniki** (30%):
   - OsiÄ…gniÄ™ta accuracy
   - PorÃ³wnanie rÃ³Å¼nych metod

3. **Prezentacja** (20%):
   - JasnoÅ›Ä‡ przekazu
   - Wizualizacje
   - Czas (10 min)

4. **Raport/Kod** (20%):
   - JakoÅ›Ä‡ kodu
   - Dokumentacja
   - ReprodukowalnoÅ›Ä‡

---

## ğŸ’¡ WskazÃ³wki

### Do ekstrakcji cech:
- UÅ¼yj `cv2.findContours()` do wyznaczenia konturÃ³w
- `cv2.moments()` dla momentÃ³w obrazu
- `skimage.feature.greycomatrix()` dla GLCM
- Normalizuj cechy przed klasyfikacjÄ…!

### Do klasyfikacji:
- UÅ¼yj `StandardScaler` przed SVM/k-NN
- Grid Search dla hyperparameters
- Zapisuj modele: `joblib.dump(model, 'model.pkl')`

### Wizualizacje:
- Confusion matrix: `plot_confusion_matrix()`
- Feature importance dla Random Forest
- t-SNE dla wizualizacji cech w 2D

---

## ğŸ› RozwiÄ…zywanie problemÃ³w

### Problem: BiaÅ‚e tÅ‚o zakÅ‚Ã³ca cechy koloru
**RozwiÄ…zanie**: Segmentacja - usuÅ„ biaÅ‚e tÅ‚o przed ekstrakcjÄ… cech

### Problem: Za duÅ¼o cech (overfitting)
**RozwiÄ…zanie**: Feature selection (SelectKBest, PCA)

### Problem: Niezbalansowane klasy
**RozwiÄ…zanie**: 
- `class_weight='balanced'` w SVM/RF
- SMOTE (oversampling)

### Problem: DÅ‚ugi czas trenowania
**RozwiÄ…zanie**: 
- UÅ¼yj podzbioru danych na poczÄ…tku (np. 10 klas)
- Zmniejsz liczbÄ™ cech

---

## ğŸ“ Kontakt i wspÃ³Å‚praca

**CzÅ‚onkowie zespoÅ‚u**:
- Osoba 1: [ImiÄ™] - [email/kontakt]
- Osoba 2: Andrii - 98598

**PodziaÅ‚ zadaÅ„**:
- Osoba 1: Preprocessing + Ekstrakcja cech koloru/ksztaÅ‚tu
- Osoba 2: Ekstrakcja cech tekstury + Klasyfikacja

**Termin prezentacji**: Ostatnie zajÄ™cia laboratoryjne

---

## ğŸ”„ Historia zmian

- **2026-01-18**: 
  - âœ… UkoÅ„czono notebook `01_eksploracja_danych_v2.ipynb`
  - Dodano komentarze z dokumentacjÄ… i ÅºrÃ³dÅ‚ami do wszystkich komÃ³rek
  - Zaktualizowano README.md i CURSOR.md do rzeczywistych statystyk (48 klas, 47,033 obrazÃ³w)
  - Zaimplementowano: preprocessing, segmentacjÄ™, CLAHE, LBP, shape features, augmentacjÄ™
- **2025-11-09**: Utworzenie projektu, wybÃ³r datasetu Fruits 360, struktura katalogÃ³w

---

**Powodzenia! ğŸ€**

